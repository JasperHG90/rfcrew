# [Infrastructure] Choose an orchestrator

|                 |                                                                                                                                                              |
| :-------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Author**      | @Ginn, Jasper                                                                                                                                                |
| **Reviewers**   |                                                                                                                                                              |
| **Ticket**      |                                                                                                                                                              |
| **Date**        | 27/02/2025                                                                                                                                                   |
| **Final decision** | Composer is the obvious choice. This needs to be hashed out a little more in terms of pricing and (domain) architecture. This RFC will be revisited when approved by the architecture board. |
| **Version**     | v0.0.1                                                                                                                                                       |

## Overview ðŸ”—

The Sligro EDP does not have an orchestrator. This is causing issues with overview, failure detection, change tracking, and adaptability. Moreover, we need to anticipate future workflows in which orchestration will be indispensable, such as managing multiple ODS deployments.

The requirements for a new orchestrator include easy accessibility, quick familiarization, testing without deployment, comprehensive pipeline overview, clear failure display, source control updates, and integration with other tools.

Two options are considered: Airflow (Composer or Astronomer), Dagster. Pros and cons are listed for each option, along with associated costs.

## Table of contents ðŸ”—

*   Overview
*   Table of contents
*   Changelog
*   Goals and Requirements
*   Audience
*   Context and Scope
*   Options
*   Costs
*   Current Use
*   Future Use
*   Recommendation
*   Impact
*   Discussion
*   Follow-ups
*   Related

## Changelog ðŸ”—

| Version | Changes       |
| :------ | :------------ |
| v0.1    | First version |

## Goals and Requirements ðŸ”—

From users:

*   Tool should be easily accessible
*   Easy to quickly get familiar with using and configuring the tool
*   Pipelines should be easy to test without requiring a deployment
*   Tool should provide a comprehensive overview of the various pipelines run for ingestion and transformation of data
*   Failures should clearly displayed and allow for some basic diagnostics of the underlying issue
*   Updates to the tool should be possible via source control such that there is versioning and a change review process

## Audience ðŸ”—

This change primarily affects Data Engineers as they need to refactor/migrate existing workflows

## Context and Scope ðŸ”—

The current orchestration setup for the Sligro EDP is split across different tools. Most data products are triggered from CRON schedules defined on GCP. Others, like ODS, are triggered based on incoming webhooks. This is problematic in terms of:

*   Having a good overview
*   Detecting / identifying failures
*   Keeping track of changes to the orchestration
*   Ensuring changes are reviewed
*   Lack of boilerplate code for situations that demand additional technical requirements (e.g. Fivetran webhook or Ingestor rate limiter).
*   Disjointed schedules for ingestion and transformation pipelines.

The orchestrator needs to:

*   Trigger Fivetran ingestion pipelines
*   Trigger transformation pipelines with dbt cloud
*   Trigger GCP resources (e.g. functions, cloud run jobs)
*   Support integration with other tooling
*   Support sensors to detect if all preconditions have been met before kicking off the next part of a pipeline
*   Be able to queue or defer workloads that cannot run simultaneously (e.g. ODS)

## Options ðŸ”—

|         | Option 1                                                                                                                                                                                               | Option 2                                                                                                                                                                                                                             |
| :------ | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Tool**  | Airflow                                                                                                                                                                                                | Dagster                                                                                                                                                                                                                              |
| **Link**  | [airflow.apache.org](https://airflow.apache.org)                                                                                                                                                           | [dagster.io](https://dagster.io)                                                                                                                                                                                                       |
| **Pros**  | â€¢ Mature tool<br>â€¢ Big community<br>â€¢ DAG defined in code<br>â€¢ Open source<br>â€¢ Lots of connectors including Fivetran, dbt Cloud, and BigQuery<br>â€¢ Many hosting options<br>â€¢ Supports SSO with Entra ID | â€¢ Improved over Airflow<br>â€¢ Nice DBT integration<br>â€¢ Easier to develop with than Airflow due to developer-first experience.<br>â€¢ Separates business logic from infra<br>â€¢ Lightweight to run (no scheduler required)<br>â€¢ Good testing support<br>â€¢ DAG defined in code<br>â€¢ SSO available via Entra ID |
| **Cons**  | â€¢ Not everyone knows Python<br>â€¢ Local testing hard<br>â€¢ Pipeline bound to execution environment<br>â€¢ Running upgrades (depending on version)<br>â€¢ Requires procurement<br>â€¢ Exposing logs is fiddly<br>â€¢ DBT DAG mapping not natively supported | â€¢ Small community (321 contributors vs 2,594)<br>â€¢ Not everyone knows Python<br>â€¢ It's a big unknown for upgrades, scalability,<br>â€¢ Requires procurement                                                                      |
| **Other** | Task-centric                                                                                                                                                                                           | â€¢ Data-centric<br>â€¢ Hybrid deployment mode available (metadata on dagster cloud, data on GCP)                                                                                                                                         |
| **Costs** | See Option 1 A&B below                                                                                                                                                                               | [link]() (Note: Link URL missing in OCR)                                                                                                                                                                                             |

**Option 1 - A & B**

|          | Option 1A                                                                                                                                                                                                                                                              | Option 1B                                                                                                                                       |
| :------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------- |
| **Context**| Astronomer                                                                                                                                                                                                                                                             | GCP Cloud Composer                                                                                                                              |
| **Link**   | [astronomer.io](https://astronomer.io)                                                                                                                                                                                                                                   | [docs](https://cloud.google.com/composer/docs)                                                                                                   |
| **Pros**   | â€¢ Astronomer employees Airflow contributors<br>â€¢ Good support for getting started<br>â€¢ Astro CLI vastly improves the developer experience<br>â€¢ Latest Airflow version<br>â€¢ Airflow hosting managed by Astronomer. Hybrid execution model available with control over self-hosted execution environment. See [docs](https://docs.astronomer.io/).<br>â€¢ Fine-grained control over DAG runtime docker image.<br>â€¢ Amazing documentation.<br>â€¢ Support for many different kinds of executors.<br>â€¢ GitHub integration for CI/CD | â€¢ Integrated with GCP services, including logging, secret manager, cloud run and cloud functions<br>â€¢ Easy to get started: just deploy an instance<br>â€¢ IAM integration for access control |
| **Cons**   | â€¢ Can update in-place<br>â€¢ No direct log integration with GCP logging                                                                                                                                                                                                  | â€¢ No local development environment. Can probably use the Astro CLI workflow to develop locally.<br>â€¢ Hard to control the DAG runtime docker container. DAGs are synced via cloud storage.<br>â€¢ Supports only blocked executors. |
| **Other**  | â€¢ Dags deployed via astro tool<br>â€¢ No data in Astronomer, but metadata yes<br>â€¢ Hosting in GCP/AWS                                                                                                                                                                    | â€¢ Dags added via storage account                                                                                                                |
| **Costs**  | [link]() (Note: Link URL missing in OCR)                                                                                                                                                                                                                               | [link]() (Note: Link URL missing in OCR)                                                                                                        |

## Costs ðŸ”—

### Current Use ðŸ”—

Based loosely on current use, we'd need something like this for Production

*   A workflow to orchestrate ingestion, modelling and serving workflows, run on a daily basis
*   An ingestion workflow to trigger 10 Fivetran resources dbt jobs, cloud run jobs, and cloud functions

For Development:

*   The ability to verify workflows against our infrastructure

Per option:

**Option 1A - Airflow Astronomer**

Info: ðŸ”— [Astronomer (Astro) Pricing - Transparent & Flexible at Scale](https://www.astronomer.io/pricing/)

*   choice between "Pay As You Go" or "Custom"
*   "Pay As You Go" -> $0.35+/hr per deployment
*   Cost is (Deployment Cost) + (Worker Cost)
*   Deployment could be 24/7 Production and Development - create/delete as needed

Astronomer provides some pricing scenarios:

Standard - 100 DAGS - $934.40 per month
*   Production Deployment (Medium Scheduler, Two A10 Workers)
*   Dev Deployment (Small Scheduler, One A5 Worker)

Light - 10-50 DAGs - $350.40 per month
*   Small Scheduler & One A5 worker

**Option 1B - Cloud Composer**

With two composer instances running (one small, one medium), we would pay +-$1.100-$2.000 per month according to the [pricing calculator](https://cloud.google.com/products/calculator/#id=16f5e5e8-a2d4-4d8a-8e3b-7b2e7a3c9d7f) (Note: Link is generic, specific calculation might be needed).

**Option 2 - Dagster**

*   Team - $100 per month, 3 users (unlimited viewers), $0.005 per serverless compute minute. 30K materializations.
*   Enterprise - "Contact sales", $0.005 per serverless

This would cost +-$1200 / month

## Future Use ðŸ”—

Considerations:

*   More data sources added
*   Additional transformations added

So maybe:

*   Longer run time
*   More compute

## Recommendation ðŸ”—

The Astronomer runtime gives us more control over the development environment and the runtime environment, which is really nice and far superior over what Composer offers. It's also less expensive, although running the hybrid execution model would add costs for hosting our own Kubernetes clusters.

The trade-off between these two comes down to ease-of-setup v. customizability. The fact that Composer offers no control over the runtime environment is ultimately something that could become a blocker for data engineering work, as well as the limited executor support.

## Impact ðŸ”—

This is an entirely different way-of-working than what we've done until now.

We probably need a migration strategy for current data products (if necessary), so that all workloads that need to be scheduled are orchestrated from the solution that we pick.

## Discussion ðŸ”—

Lack of control over runtime execution environment makes Composer less attractive than Astronomer. The latter also adds a lot of additional tools to streamline DAG development and supports more complex DAGs. However, it's easy to start with composer and possibly migrate to Astronomer later if desired.

## Follow-ups ðŸ”—

Place follow-up work here

## Related ðŸ”—

Place related RFCs, ADRs or other documents here
